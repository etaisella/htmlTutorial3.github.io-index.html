<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
    <link href='https://fonts.googleapis.com/css?family=Noto Sans' rel='stylesheet'>
    <link href='https://fonts.googleapis.com/css?family=Indie Flower' rel='stylesheet'>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Vox-E: Text-guided Voxel Editing of 3D Objects</title>
<!--    <link rel="icon" href="../pics/wis_logo.jpg">-->
    <link rel="icon" href="images/browser_icon.png">
    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/swiper@9/swiper-bundle.min.css">
    <link href="./style.css" rel="stylesheet" type="text/css">
</head>
<script type="text/javascript">
    src=hover.js;
</script>
<body>
<div class="page-container" >
    <script src="https://cdn.jsdelivr.net/npm/swiper@9/swiper-bundle.min.js"></script>

    <!-- title -->
    <h1 align="center">Vox-E</h1>
    <h2 align="center">Text-guided Voxel Editing of 3D Objects</h2>

    <!-- authors and affiliations -->
    <section class="authors_block">
        <div class="authors" align="center">
            <span class="author-block"><a target="https://www.linkedin.com/in/etai-sella-1792b2154/" target="_blank">Etai Sella</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://www.linkedin.com/in/gal-fiebelman-b923031b4/" target="_blank">Gal Fiebelman</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://phogzone.com/" target="_blank">Peter Hedman</a><sup>2</sup>,</span>
            <span class="author-block"><a href="https://www.elor.sites.tau.ac.il/" target="_blank">Hadar Averbuch-Elor</a><sup>1</sup></span>
        </div>

        <div class="affiliations" align="center">
            <span class="author-block"><sup>1</sup>Tel Aviv University, </span>
            <span class="author-block"><sup>2</sup>Google Research</span>
        </div>
    </section>

    <!-- link buttons -->
    <div class="column has-text-centered">
        <div class="publication-links" align="center">
          
          <!-- arxiv link -->
          <span class="link-block">
            <!--<a href="none"> -->
                <button class="button" target="_blank">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv (Coming Soon)</span>
                  </button>
            <!-- </a> -->
          </span>
          
          <!-- Github Link. -->
          <span class="link-block">
            <!-- <a href="none"> -->
                <button class="button">
                    <span class="icon">
                        <i class="fa fa-github"></i>
                    </span>
                    <span>Code (Coming Soon)</span>
                  </button>
            <!-- </a> -->
          </span>
        </div>
    </div>

    <!-- slider -->
    <!-- Slider main container -->
    <div class="swiper">
        <!-- Additional required wrapper -->
        <div class="swiper-wrapper">
          <!-- Slides -->
          <!-- Slide 1 -->
          <div class="swiper-slide">
            <table class="slide-table" width="100%" align="center">
                <tbody>
                    <tr>
                        <th colspan="2" width="90%" class="prompt_title_local">"A kangaroo on rollerskates"</th>
                    </tr>
                    <tr>
                        <td colspan="2">
                            <video loop autoplay  muted width="95%"  class="result-video">
                                <source src=".\videos\kangaroo_rollerskates_merged.mp4" type="video/mp4">
                            </video>
                        </td>
                    </tr>
                    <tr>
                        <td width="45%">
                            <div align="center" class="video-label-slides">Initial</div>
                        </td>
                        <td width="41%">
                            <div align="center" class="video-label-slides">Edited&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</div>
                        </td>
                    </tr>
                </tbody>
            </table>
          </div>
          <!-- Slide 2 -->
          <div class="swiper-slide">
            <table class="slide-table" width="100%" align="center">
                <tbody>
                    <tr>
                        <th colspan="2" width="90%" class="prompt_title">"A dog in low-poly video game style"</th>
                    </tr>
                    <tr>
                        <td colspan="2">
                            <video loop autoplay  muted width="95%"  class="result-video">
                                <source src=".\videos\dog_lowpoly_merged.mp4" type="video/mp4">
                            </video>
                        </td>
                    </tr>
                    <tr>
                        <td width="45%">
                            <div align="center" class="video-label-slides">Initial</div>
                        </td>
                        <td width="41%">
                            <div align="center" class="video-label-slides">Edited&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</div>
                        </td>
                    </tr>
                </tbody>
            </table>
          </div>
          <!-- Slide 3 -->
          <div class="swiper-slide">
            <table class="slide-table" width="100%" align="center">
                <tbody>
                    <tr>
                        <th colspan="2" width="90%" class="prompt_title_local">"An alien wearing a tuxedo"</th>
                    </tr>
                    <tr>
                        <td colspan="2">
                            <video loop autoplay  muted width="95%"  class="result-video">
                                <source src=".\videos\alien_tuxedo_merged.mp4" type="video/mp4">
                            </video>
                        </td>
                    </tr>
                    <tr>
                        <td width="45%">
                            <div align="center" class="video-label-slides">Initial</div>
                        </td>
                        <td width="41%">
                            <div align="center" class="video-label-slides">Edited&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</div>
                        </td>
                    </tr>
                </tbody>
            </table>
          </div>
          <!-- Slide 4 -->
          <div class="swiper-slide">
            <table class="slide-table" width="100%" align="center">
                <tbody>
                    <tr>
                        <th colspan="2" width="90%" class="prompt_title_local">"A black swan"</th>
                    </tr>
                    <tr>
                        <td colspan="2">
                            <video loop autoplay  muted width="95%"  class="result-video">
                                <source src=".\videos\duck_black_swan_merged.mp4" type="video/mp4">
                            </video>
                        </td>
                    </tr>
                    <tr>
                        <td width="45%">
                            <div align="center" class="video-label-slides">Initial</div>
                        </td>
                        <td width="41%">
                            <div align="center" class="video-label-slides">Edited&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</div>
                        </td>
                    </tr>
                </tbody>
            </table>
          </div>
          <!-- Slide 5 -->
          <div class="swiper-slide">
            <table class="slide-table" width="100%" align="center">
                <tbody>
                    <tr>
                        <th colspan="2" width="90%" class="prompt_title_local">"A cactus in a pot"</th>
                    </tr>
                    <tr>
                        <td colspan="2">
                            <video loop autoplay  muted width="95%"  class="result-video">
                                <source src=".\videos\ficus_cactus_merged.mp4" type="video/mp4">
                            </video>
                        </td>
                    </tr>
                    <tr>
                        <td width="45%">
                            <div align="center" class="video-label-slides">Initial</div>
                        </td>
                        <td width="41%">
                            <div align="center" class="video-label-slides">Edited&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</div>
                        </td>
                    </tr>
                </tbody>
            </table>
          </div>

        </div>
        <!-- If we need pagination -->
        <div class="swiper-pagination"></div>
    
        <!-- If we need navigation buttons -->
        <div class="swiper-button-prev"></div>
        <div class="swiper-button-next"></div>
    </div>

    <!-- intro -->
    <section class="into-paragraph-section" width="100%">
        <div class="intro-container">
            <div class="intro-paragraph">
                <p>
                    Given multiview images of an object, our technique enables generating volumetric edits from target text prompts. The
                    objects can be edited either locally (presented with a <span class="prompt_title_local">green</span> prompt) or globally, 
                    depending on the nature of the user-provided text prompt.
                    Our technique enables for incorporating significant geometric and appearance changes, while faithfully preserving the input object.
                </p>
            </div>
        </div>
    </section>

    <!-- abstract -->
    <section class="abstract-section" width="100%">
        <div class="abstract-container">
            <hr>
            <h2 align="left">Abstract</h2>
            <table class="abstract-table" width="100%" align="center" margin-top="-23px">
                <tbody>
                    <tr>
                        <td width="75%" align="left">
                            <p>
                                Large scale text-guided diffusion models have garnered significant attention due to their ability to synthesize diverse images that convey complex visual concepts. 
                                This generative power has more recently been leveraged to perform text-to-3D synthesis. 
                                In this work, we present a technique that harnesses the power of latent diffusion models for editing existing 3D objects.
                                Our method takes oriented 2D images of a 3D object as input and learns a grid-based volumetric representation of it.
                                To guide the volumetric representation to conform to a target text prompt, we follow unconditional text-to-3D methods and optimize a Score Distillation Sampling (SDS) loss. 
                                However, we observe that combining this diffusion-guided loss with an image-based regularization loss that encourages the representation not to deviate too strongly from the input object
                                is challenging, as it requires achieving two conflicting goals while viewing only structure-and-appearance coupled 2D projections. 
                                Thus, we introduce a novel volumetric regularization loss that operates directly in 3D space, utilizing the explicit nature of our 3D representation to enforce correlation between the global structure of the original and edited object. 
                                Furthermore, we present a technique that optimizes cross-attention volumetric grids to refine the spatial extent of the edits.
                                Extensive experiments and comparisons demonstrate the effectiveness of our approach in creating a myriad of edits  which cannot be achieved by prior works.
                            </p>
                        </td>
                        <td width="25%" align="center">
                            <img src="images/paper_thumbnail_cropped.png" alt="Paper Thumbnail" width="80%">
                        </td>
                    </tr>
                </tbody>
            </table>
        </div>
    </section>

    <!-- method -->
    <section class="method-section" width="100%">
        <div class="method-container">
            <hr>
            <h2 align="left">How it Works</h2>
            <img src="images/overview_official.png" alt="Overview" width="90%">
            <p>
                Given a set of posed multi-view images of an object (for example a kangaroo) we start by learning a 3D voxel-grid based 
                representation which reconstructs the object depicted in the images. We then begin iteratively editing this voxel-grid according
                to a given text prompt (for example "a kangaroo on rollerskates") using Score Distillation Sampling. We regularize this process 
                at each iteration by encouraging similarity between the structure of the edited grid and the original object reconstructing grid.
                While producing good results for a variety of edits, this method does not support hyper-localized edits where nothing changes except for 
                a specific part of the object. To account for this, we introduce an additional, optional, stage we call the "Refinement Stage". In this 
                stage we extract cross-attention maps from a Latent Diffusion Model (LDM) for the edit word token (i.e. "rollerskates") and the object 
                related tokens (i.e "a kangaroo") to train volumetric "attention grids" for the edit and object. Using these grids we estimate a 
                volumetric mask which labels each voxel in the edited grid as either "object" or "edit" and use this mask to replace all the "object"
                labled voxels with the matching voxels in the initial reconstruction grid.

            </p>

        </div>
    </section>

    <!-- Acknowledgements -->
    <section class="ack-section" width="100%">
        <div class="ack-container">
            <hr>
            <h2 align="left">Acknowledgements</h2>
            <p>
                We would like to acknowledge such and such for this and that.
            </p>

        </div>
    </section>

  <p><br>
  </p>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
  <p>&nbsp;</p>

</div>
<script>
const swiper = new Swiper('.swiper', {
    autoplay: {
    delay: 4000,
    },
    // Optional parameters
    speed: 1000,
    loop: true,
  
    // If we need pagination
    pagination: {
      el: '.swiper-pagination',
    },
  
    // Navigation arrows
    navigation: {
      nextEl: '.swiper-button-next',
      prevEl: '.swiper-button-prev',
    },
  });
</script>

</body></html>
